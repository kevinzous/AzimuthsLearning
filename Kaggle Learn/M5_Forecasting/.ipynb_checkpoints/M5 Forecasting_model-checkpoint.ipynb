{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# ploting\n",
    "'''from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "'''\n",
    "# modeling\n",
    "import statsmodels.formula.api as smf\n",
    "'''import statsmodels.api as sm\n",
    "import statsmodels.tsa.arima_process as sta\n",
    "import statsmodels.graphics.tsaplots as sgt\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import statsmodels.tsa.statespace as sts\n",
    "'''\n",
    "from sklearn import preprocessing,metrics , model_selection\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline solution 1 : mean (score : 1.69158)\n",
    "'''\n",
    "sales_train_validation, calendar, sell_prices, sample_submission = read_data('data')\n",
    "sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "\n",
    "mean_sales=sales_train_validation.mean(axis=1,numeric_only=True)\n",
    "mean=mean_sales.append(mean_sales).reset_index(drop=True)\n",
    "for col in ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
    "          'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', \n",
    "          'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']:\n",
    "    sample_submission[col]=mean  \n",
    "    \n",
    "sample_submission.to_csv(\"submission_mean.csv\",index=False)\n",
    "'''\n",
    "# baseline solution 2 : zeros before trimmed + mean (score : 1.20619)\n",
    "'''\n",
    "sales_train_validation, calendar, sell_prices, sample_submission = read_data('data')\n",
    "sales_train_validation = reduce_mem_usage(sales_train_validation)\n",
    "\n",
    "my_array=sales_train_validation.iloc[:,6:].values\n",
    "sub=[np.mean(np.trim_zeros(row)) for row in my_array]\n",
    "for col in ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10',\n",
    "          'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', \n",
    "          'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28']:\n",
    "    sample_submission[col]=sub+sub  \n",
    "    \n",
    "sample_submission.to_csv(\"submission_mean_wo_zero.csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Reading data and data manipulation (melt) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**WE FIRST WILL ONLY TAKE FIRST 10000 TIME SERIES TO EASE THE LOAD ON CPU/RAM **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    \"\"\" path : string \"\"\"\n",
    "    df1 = pd.read_csv(path+'/sales_train_validation.csv')\n",
    "    df2 = pd.read_csv(path+'/calendar.csv',parse_dates=[0])\n",
    "    df3 = pd.read_csv(path+'/sell_prices.csv')\n",
    "    df4 = pd.read_csv('data/sample_submission.csv')\n",
    "    return df1,df2,df3,df4\n",
    "\n",
    "def reduce_memory(dfs,verbose=False):\n",
    "    return [reduce_memory_usage(df) for df in dfs]\n",
    "    \n",
    "def reduce_memory_usage(df, verbose=False):\n",
    "    \"\"\"reduce memory usage of integer & float columns based on their value range\"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
    "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
    "\n",
    "    for col in int_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem)\n",
    "             )\n",
    "    return df\n",
    "\n",
    "def data_manipulation(sales_train_validation,n_samples=10000):\n",
    "    sales_train_validation = sales_train_validation[:n_samples]\n",
    "    # unpivote the columns \n",
    "    value_vars=sales_train_validation.columns.to_list()[6:]  # remove the first 6 variables ie 'id','item_id', 'dept_id', 'cat_id', 'store_id','state_id'\n",
    "    id_vars=['id','item_id', 'dept_id', 'cat_id', 'store_id','state_id']\n",
    "    sales = pd.melt(sales_train_validation,id_vars=id_vars, value_vars=value_vars,var_name='d', value_name='sales_count')\n",
    "    \n",
    "    # join with calendar\n",
    "    sales=pd.merge(sales,calendar,left_on='d',right_on='d',how=\"left\")\n",
    "    # join with selling price\n",
    "    # seperate test dataframes\n",
    "    '''sales_validation_id = [row for row in sample_submission['id'] if 'validation' in row]\n",
    "    sales_evaluation_id = [row for row in sample_submission['id'] if 'evaluation' in row]\n",
    "\n",
    "    sales_validation = sample_submission[sample_submission['id'].isin(sales_validation_id)]\n",
    "    sales_evaluation = sample_submission[sample_submission['id'].isin(sales_evaluation_id)]\n",
    "    '''\n",
    "    # free memory\n",
    "    del id_vars,value_vars\n",
    "    return sales #,sales_validation,sales_evaluation\n",
    "\n",
    "def feature_engineering(sales):\n",
    "    # drop useless columns\n",
    "    useless_cols=[\"d\",\"wm_yr_wk\",\"wday\",\"weekday\"]\n",
    "    sales.drop(columns=useless_cols,inplace=True)\n",
    "    \n",
    "    # fill nan\n",
    "    nan_cols=[\"event_name_1\",\"event_type_1\",\"event_name_2\",\"event_type_2\"]\n",
    "    for col in nan_cols:\n",
    "        sales[col].fillna('Nothing',inplace=True)\n",
    "    \n",
    "    # encode categorical\n",
    "    '''cat_cols=[\"item_id\",\"dept_id\",\"store_id\",\"state_id\",\"cat_id\",\"weekday\"]+nan_cols\n",
    "    encoder = preprocessing.OneHotEncoder()\n",
    "    for col in cat_cols:\n",
    "        sales[col]= encoder.fit_transform(sales[col])''' \n",
    "\n",
    "    # feature engineering\n",
    "    '''source : https://kanoki.org/2019/09/09/how-to-shift-a-column-in-pandas/ \n",
    "    => use groupby + transform to see the separate value for each group.'''\n",
    "    \n",
    "    # sales series features\n",
    "    '''1- groupby id (ie timeseries (10000 series)\n",
    "       2- take the sales_count of 28 days before of that same series\n",
    "       3- the sales found at column lag_28 in row i will be found in the column sales_count at 28*n_sample + i \n",
    "       4- temp.iloc[28*10000+i]==sales.iloc[i,6]'''\n",
    "    sales['lag_1d']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(1))\n",
    "    sales['lag_2d']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(2))\n",
    "    sales['lag_3d']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(3))\n",
    "    sales['lag_1w']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(7))\n",
    "    sales['lag_2w']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(14))\n",
    "    sales['lag_4w']=sales.groupby(['id'])['sales_count'].transform(lambda x: x.shift(28))\n",
    "    \n",
    "    sales['rolling_avg_1w']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(7,min_periods=1).mean())\n",
    "    sales['rolling_avg_1m']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(30,min_periods=1).mean())\n",
    "    sales['rolling_avg_6m']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(180,min_periods=1).mean())\n",
    "    sales['rolling_avg_1y']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(365,min_periods=1).mean())\n",
    "    \n",
    "    sales['rolling_std_1w']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(7,min_periods=1).std())\n",
    "    sales['rolling_std_1m']=sales.groupby(['id'])['sales_count'].transform(lambda x : x.rolling(30,min_periods=1).std())\n",
    "    \n",
    "    # time features \n",
    "    date_cols=[\"date\",\"year\",\"month\"]\n",
    "    sales['dayofweek']=sales.date.dt.dayofweek\n",
    "    sales['dayofmonth']=sales.date.dt.day\n",
    "    \n",
    "    \n",
    "    # drop nan due to the rolling function\n",
    "    initial_len=len(sales)\n",
    "    sales.dropna(inplace=True)\n",
    "    print('Dropped',initial_len-len(sales), 'rows out of', initial_len, 'initially')\n",
    "    \n",
    "    sales = reduce_memory_usage(sales,verbose=True)\n",
    "    return sales\n",
    "\n",
    "def model_fitting(y, feature_set, sales):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    formula = y + '~' + '+'.join(feature_set)\n",
    "    # fit the regression model\n",
    "    model = smf.ols(formula=formula, data=sales).fit()\n",
    "    return model\n",
    "def model_eval(y, feature_set, sales):\n",
    "    y=sales['y']\n",
    "    X=sales.drop(columns=[y])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    model=model_fitting(y, feature_set, y_train+X_train)\n",
    "    pred=model.predict(X_test)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    \n",
    "def predict():\n",
    "    pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it has taken 239.4926779270172 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sales_train_validation, calendar, sell_prices, sample_submission = read_data('data')\n",
    "sales_train_validation, calendar, sell_prices = reduce_memory([sales_train_validation,\n",
    "                                                              calendar,\n",
    "                                                              sell_prices])\n",
    "end = time.time()\n",
    "print(\"it has taken\",end-start,\"seconds\") # 210 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it has taken 1.1350421905517578 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sales = data_manipulation(sales_train_validation,n_samples=1000)    \n",
    "end = time.time()\n",
    "print(\"it has taken\",end-start,\"seconds\") # 15 s - 25 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 28000 rows out of 1913000 initially\n",
      "Mem. usage decreased to 276.84 Mb (28.7% reduction)\n",
      "it has taken 21.03753685951233 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sales = feature_engineering(sales)\n",
    "end = time.time()\n",
    "print(\"it has taken\",end-start,\"seconds\") #  235 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>sales_count</td>   <th>  R-squared:         </th>  <td>   0.575</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.575</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>7.076e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Mar 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:03:37</td>     <th>  Log-Likelihood:    </th> <td>-3.6150e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>1885000</td>     <th>  AIC:               </th>  <td>7.230e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>1884963</td>     <th>  BIC:               </th>  <td>7.231e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    36</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>   -1.4042</td> <td>    1.648</td> <td>   -0.852</td> <td> 0.394</td> <td>   -4.634</td> <td>    1.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.2]</th>             <td>    0.0011</td> <td>    0.006</td> <td>    0.189</td> <td> 0.850</td> <td>   -0.011</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.3]</th>             <td> 1.262e-05</td> <td>    0.006</td> <td>    0.002</td> <td> 0.998</td> <td>   -0.011</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.4]</th>             <td>    0.0036</td> <td>    0.006</td> <td>    0.620</td> <td> 0.535</td> <td>   -0.008</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.5]</th>             <td>    0.0090</td> <td>    0.006</td> <td>    1.502</td> <td> 0.133</td> <td>   -0.003</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.6]</th>             <td>    0.0053</td> <td>    0.006</td> <td>    0.887</td> <td> 0.375</td> <td>   -0.006</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.7]</th>             <td>   -0.0013</td> <td>    0.006</td> <td>   -0.210</td> <td> 0.834</td> <td>   -0.013</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.8]</th>             <td>    0.0057</td> <td>    0.006</td> <td>    0.950</td> <td> 0.342</td> <td>   -0.006</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.9]</th>             <td>    0.0039</td> <td>    0.006</td> <td>    0.654</td> <td> 0.513</td> <td>   -0.008</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.10]</th>            <td>   -0.0005</td> <td>    0.006</td> <td>   -0.077</td> <td> 0.938</td> <td>   -0.012</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.11]</th>            <td>   -0.0112</td> <td>    0.006</td> <td>   -1.856</td> <td> 0.063</td> <td>   -0.023</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(month)[T.12]</th>            <td>    0.0215</td> <td>    0.006</td> <td>    3.606</td> <td> 0.000</td> <td>    0.010</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dept_id)[T.HOBBIES_2]</th>   <td>   -0.0041</td> <td>    0.004</td> <td>   -1.125</td> <td> 0.261</td> <td>   -0.011</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dept_id)[T.HOUSEHOLD_1]</th> <td>    0.0059</td> <td>    0.003</td> <td>    2.236</td> <td> 0.025</td> <td>    0.001</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.1]</th>         <td>   -0.0777</td> <td>    0.004</td> <td>  -17.267</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.2]</th>         <td>   -0.1837</td> <td>    0.005</td> <td>  -40.793</td> <td> 0.000</td> <td>   -0.193</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.3]</th>         <td>   -0.2745</td> <td>    0.005</td> <td>  -60.863</td> <td> 0.000</td> <td>   -0.283</td> <td>   -0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.4]</th>         <td>   -0.1761</td> <td>    0.005</td> <td>  -39.043</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.5]</th>         <td>    0.0726</td> <td>    0.005</td> <td>   16.085</td> <td> 0.000</td> <td>    0.064</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(dayofweek)[T.6]</th>         <td>    0.1374</td> <td>    0.004</td> <td>   30.545</td> <td> 0.000</td> <td>    0.129</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_1d</th>                    <td>   -0.2102</td> <td>    0.001</td> <td> -298.838</td> <td> 0.000</td> <td>   -0.212</td> <td>   -0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_2d</th>                    <td>   -0.2359</td> <td>    0.001</td> <td> -338.855</td> <td> 0.000</td> <td>   -0.237</td> <td>   -0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_3d</th>                    <td>   -0.2612</td> <td>    0.001</td> <td> -372.855</td> <td> 0.000</td> <td>   -0.263</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_1w</th>                    <td>    0.0275</td> <td>    0.001</td> <td>   42.829</td> <td> 0.000</td> <td>    0.026</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_2w</th>                    <td>    0.0296</td> <td>    0.001</td> <td>   45.799</td> <td> 0.000</td> <td>    0.028</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lag_4w</th>                    <td>    0.0356</td> <td>    0.001</td> <td>   55.456</td> <td> 0.000</td> <td>    0.034</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_avg_1w</th>            <td>    1.7891</td> <td>    0.003</td> <td>  629.843</td> <td> 0.000</td> <td>    1.784</td> <td>    1.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_avg_1m</th>            <td>   -0.1823</td> <td>    0.004</td> <td>  -50.347</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_avg_6m</th>            <td>   -0.0200</td> <td>    0.004</td> <td>   -4.910</td> <td> 0.000</td> <td>   -0.028</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_avg_1y</th>            <td>    0.0137</td> <td>    0.003</td> <td>    4.042</td> <td> 0.000</td> <td>    0.007</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_std_1w</th>            <td>   -0.0473</td> <td>    0.002</td> <td>  -24.423</td> <td> 0.000</td> <td>   -0.051</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rolling_std_1m</th>            <td>    0.0546</td> <td>    0.002</td> <td>   24.204</td> <td> 0.000</td> <td>    0.050</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dayofmonth</th>                <td>   -0.0030</td> <td>    0.000</td> <td>  -10.397</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>                      <td>    0.0008</td> <td>    0.001</td> <td>    0.932</td> <td> 0.352</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>snap_CA</th>                   <td>   -0.0169</td> <td>    0.004</td> <td>   -3.785</td> <td> 0.000</td> <td>   -0.026</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>snap_TX</th>                   <td>   -0.0202</td> <td>    0.003</td> <td>   -5.932</td> <td> 0.000</td> <td>   -0.027</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>snap_WI</th>                   <td>   -0.0095</td> <td>    0.003</td> <td>   -2.873</td> <td> 0.004</td> <td>   -0.016</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2605640.739</td> <th>  Durbin-Watson:     </th>    <td>   1.982</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>13673201788.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 6.977</td>    <th>  Prob(JB):          </th>    <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>420.006</td>   <th>  Cond. No.          </th>    <td>2.77e+06</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.77e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            sales_count   R-squared:                       0.575\n",
       "Model:                            OLS   Adj. R-squared:                  0.575\n",
       "Method:                 Least Squares   F-statistic:                 7.076e+04\n",
       "Date:                Fri, 27 Mar 2020   Prob (F-statistic):               0.00\n",
       "Time:                        00:03:37   Log-Likelihood:            -3.6150e+06\n",
       "No. Observations:             1885000   AIC:                         7.230e+06\n",
       "Df Residuals:                 1884963   BIC:                         7.231e+06\n",
       "Df Model:                          36                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=============================================================================================\n",
       "                                coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                    -1.4042      1.648     -0.852      0.394      -4.634       1.825\n",
       "C(month)[T.2]                 0.0011      0.006      0.189      0.850      -0.011       0.013\n",
       "C(month)[T.3]              1.262e-05      0.006      0.002      0.998      -0.011       0.011\n",
       "C(month)[T.4]                 0.0036      0.006      0.620      0.535      -0.008       0.015\n",
       "C(month)[T.5]                 0.0090      0.006      1.502      0.133      -0.003       0.021\n",
       "C(month)[T.6]                 0.0053      0.006      0.887      0.375      -0.006       0.017\n",
       "C(month)[T.7]                -0.0013      0.006     -0.210      0.834      -0.013       0.010\n",
       "C(month)[T.8]                 0.0057      0.006      0.950      0.342      -0.006       0.017\n",
       "C(month)[T.9]                 0.0039      0.006      0.654      0.513      -0.008       0.016\n",
       "C(month)[T.10]               -0.0005      0.006     -0.077      0.938      -0.012       0.011\n",
       "C(month)[T.11]               -0.0112      0.006     -1.856      0.063      -0.023       0.001\n",
       "C(month)[T.12]                0.0215      0.006      3.606      0.000       0.010       0.033\n",
       "C(dept_id)[T.HOBBIES_2]      -0.0041      0.004     -1.125      0.261      -0.011       0.003\n",
       "C(dept_id)[T.HOUSEHOLD_1]     0.0059      0.003      2.236      0.025       0.001       0.011\n",
       "C(dayofweek)[T.1]            -0.0777      0.004    -17.267      0.000      -0.086      -0.069\n",
       "C(dayofweek)[T.2]            -0.1837      0.005    -40.793      0.000      -0.193      -0.175\n",
       "C(dayofweek)[T.3]            -0.2745      0.005    -60.863      0.000      -0.283      -0.266\n",
       "C(dayofweek)[T.4]            -0.1761      0.005    -39.043      0.000      -0.185      -0.167\n",
       "C(dayofweek)[T.5]             0.0726      0.005     16.085      0.000       0.064       0.081\n",
       "C(dayofweek)[T.6]             0.1374      0.004     30.545      0.000       0.129       0.146\n",
       "lag_1d                       -0.2102      0.001   -298.838      0.000      -0.212      -0.209\n",
       "lag_2d                       -0.2359      0.001   -338.855      0.000      -0.237      -0.235\n",
       "lag_3d                       -0.2612      0.001   -372.855      0.000      -0.263      -0.260\n",
       "lag_1w                        0.0275      0.001     42.829      0.000       0.026       0.029\n",
       "lag_2w                        0.0296      0.001     45.799      0.000       0.028       0.031\n",
       "lag_4w                        0.0356      0.001     55.456      0.000       0.034       0.037\n",
       "rolling_avg_1w                1.7891      0.003    629.843      0.000       1.784       1.795\n",
       "rolling_avg_1m               -0.1823      0.004    -50.347      0.000      -0.189      -0.175\n",
       "rolling_avg_6m               -0.0200      0.004     -4.910      0.000      -0.028      -0.012\n",
       "rolling_avg_1y                0.0137      0.003      4.042      0.000       0.007       0.020\n",
       "rolling_std_1w               -0.0473      0.002    -24.423      0.000      -0.051      -0.044\n",
       "rolling_std_1m                0.0546      0.002     24.204      0.000       0.050       0.059\n",
       "dayofmonth                   -0.0030      0.000    -10.397      0.000      -0.004      -0.002\n",
       "year                          0.0008      0.001      0.932      0.352      -0.001       0.002\n",
       "snap_CA                      -0.0169      0.004     -3.785      0.000      -0.026      -0.008\n",
       "snap_TX                      -0.0202      0.003     -5.932      0.000      -0.027      -0.013\n",
       "snap_WI                      -0.0095      0.003     -2.873      0.004      -0.016      -0.003\n",
       "==============================================================================\n",
       "Omnibus:                  2605640.739   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      13673201788.257\n",
       "Skew:                           6.977   Prob(JB):                         0.00\n",
       "Kurtosis:                     420.006   Cond. No.                     2.77e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.77e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','month', 'event_name_1',\n",
    "                        'event_type_1','event_name_2', 'event_type_2','dayofweek']\n",
    "categorical_features = ['C('+feature+')' for feature in categorical_features]\n",
    "numerical_features = ['snap_CA', 'snap_TX', 'snap_WI','lag_1d', 'lag_2d', 'lag_3d', 'lag_1w', 'lag_2w',\n",
    "                      'lag_4w', 'rolling_avg_1w', 'rolling_avg_1m', 'rolling_avg_6m', 'rolling_avg_1y',\n",
    "                      'rolling_std_1w', 'rolling_std_1m','dayofmonth','year']\n",
    "                      # eventually move to categorical :  dayofmonth, year\n",
    "\n",
    "feature_set = categorical_features + numerical_features\n",
    "\n",
    "time_features = ['lag_1d', 'lag_2d', 'lag_3d', 'lag_1w', 'lag_2w','lag_4w', 'rolling_avg_1w', \n",
    "                 'rolling_avg_1m', 'rolling_avg_6m', 'rolling_avg_1y','rolling_std_1w', 'rolling_std_1m',\n",
    "                 'C(month)','C(dept_id)', 'C(store_id)','C(dayofweek)','dayofmonth','year','snap_CA', 'snap_TX', 'snap_WI']\n",
    "                # R2 = 0.575\n",
    "model = model_fitting('sales_count', time_features, sales)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y='sales_count'\n",
    "y=sales[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sales.drop(columns=['sales_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U6'), dtype('<U6')) -> dtype('<U6')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b, **eval_kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U6'), dtype('<U6')) -> dtype('<U6')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-dbce2306820a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_fitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-fb2b9679a311>\u001b[0m in \u001b[0;36mmodel_fitting\u001b[0;34m(y, feature_set, sales)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_fitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Fit model on feature_set and calculate RSS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'~'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;31m# fit the regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m         return construct_result(\n\u001b[1;32m   1050\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_fill_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_upcast_putmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U6'), dtype('<U6')) -> dtype('<U6')"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train['sales_count']=y_train.to_list()\n",
    "model=model_fitting(y, feature_set, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(X_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    \n",
    "model = modelFitting('sales_count', feature_set, sales)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "''' \n",
    "test=pd.DataFrame([2,3,4,5,7])\n",
    "test['id']=['a','b','b','b','a']\n",
    "\n",
    "print(test)\n",
    "print(\"--------\")\n",
    "print(test.groupby(['id']).rolling(2,min_periods=1).mean())\n",
    "print(\"--------\")\n",
    "print(\"with transform: \")\n",
    "print(test.groupby(['id'])[0].transform(lambda x: x.rolling(2,min_periods=1).mean()))\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function needed for calculating interval of prediction\n",
    "    fit = modal \n",
    "    exog = new dataframe'''\n",
    "    \n",
    "def transform_exog_to_model(fit, exog):\n",
    "    transform=True\n",
    "    self=fit\n",
    "\n",
    "    # The following is lifted straight from statsmodels.base.model.Results.predict()\n",
    "    if transform and hasattr(self.model, 'formula') and exog is not None:\n",
    "        from patsy import dmatrix\n",
    "        exog = dmatrix(self.model.data.orig_exog.design_info.builder, exog)\n",
    "\n",
    "    if exog is not None:\n",
    "        exog = np.asarray(exog)\n",
    "        if exog.ndim == 1 and (self.model.exog.ndim == 1 or self.model.exog.shape[1] == 1):\n",
    "            exog = exog[:, None]\n",
    "        exog = np.atleast_2d(exog)  # needed in count model shape[1]\n",
    "\n",
    "    # end lifted code\n",
    "    return exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasttime=pd.Timestamp('2017-12-22 16:00:00')\n",
    "\n",
    "x_pred_index_no = range(40000,40500)\n",
    "x_pred_time = [lasttime+i*pd.Timedelta('1:00:00') for i in range (1, len(x_pred_index_no)+1)]\n",
    "\n",
    "newdf = pd.DataFrame(index=x_pred_time,columns=['index_no'], data= x_pred_index_no)\n",
    "\n",
    "newdf['year']=newdf.index.year-2012\n",
    "newdf['monthofyear']=newdf.index.month\n",
    "newdf['dayofmonth']=newdf.index.day\n",
    "newdf['dayofweek']=newdf.index.dayofweek\n",
    "newdf['hour']=newdf.index.hour\n",
    "\n",
    "y_pred = model.predict(newdf)\n",
    "transformed_exog = transform_exog_to_model(model, newdf)\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "prstd, iv_l, iv_u = wls_prediction_std(model, transformed_exog, weights=[1])\n",
    "\n",
    "train1_partial=train1['2017-12':]\n",
    "fig, ax = plt.subplots(figsize=(24, 6))\n",
    "ax.plot(train1_partial['index_no'], train1_partial['TrafficVolume'])\n",
    "ax.scatter(train1_partial['index_no'], train1_partial['TrafficVolume'])\n",
    "fig.suptitle('Prediction Intervals')\n",
    "ax.grid(True)\n",
    "ax.plot(list(x_pred_index_no), y_pred, '-', color='red', linewidth=2)\n",
    "# interval for observations\n",
    "ax.fill_between(x_pred_index_no, iv_l, iv_u, color='#888888', alpha=0.3)\n",
    "ax.axis('tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
